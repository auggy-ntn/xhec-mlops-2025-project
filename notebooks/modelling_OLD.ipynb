{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you should implement a first version of a working machine learning model to predict the age of an Abalone.\n",
    "\n",
    "A few guidelines:\n",
    "- The model does not have to be complex. A simple linear regression model is enough.\n",
    "- You should use MLflow to track your experiments. You can use the MLflow UI to compare your experiments.\n",
    "- Do not push any MLflow data to the repository. Only the code to run the experiments is interesting and should be pushed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import mlflow.sklearn\n",
    "\n",
    "client = MlflowClient()\n",
    "# Display available experiments\n",
    "experiments = client.search_experiments()\n",
    "for exp in experiments:\n",
    "    print(f\"Experiment ID: {exp.experiment_id}, Name: {exp.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/abalone.csv')\n",
    "# df_y = df['Rings']\n",
    "# df = df.drop('Rings', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"One-hot encode the the categorical variable 'Sex' in the abalone dataset.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe with all columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with the 'Sex' column one-hot encoded.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    sex_encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "    sex_encoded = sex_encoder.fit_transform(df[[\"Sex\"]])\n",
    "    sex_feature_names = sex_encoder.get_feature_names_out([\"Sex\"])\n",
    "    sex_df = pd.DataFrame(sex_encoded, columns=sex_feature_names, index=df.index)\n",
    "    df = df.drop(\"Sex\", axis=1)\n",
    "    df_encoded = pd.concat([df, sex_df], axis=1)\n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "def scale(df: pd.DataFrame, scaler: Optional[StandardScaler] = None) -> Tuple[pd.DataFrame, StandardScaler]:\n",
    "    \"\"\"Scale the numerical features in the abalone dataset using StandardScaler.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe with all columns.\n",
    "        scaler (Optional[StandardScaler], optional): An existing StandardScaler to use for transformation.\n",
    "            If None, a new scaler will be created and fitted. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, StandardScaler]: A tuple containing the scaled dataframe and the scaler used.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    numerical_cols = [\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\", \"Viscera weight\", \"Shell weight\"]\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "    else:\n",
    "        df[numerical_cols] = scaler.transform(df[numerical_cols])\n",
    "    return df, scaler\n",
    "\n",
    "\n",
    "def preprocess_data(\n",
    "    df: pd.DataFrame, scaler: Optional[StandardScaler] = None, with_target: bool = True\n",
    ") -> Tuple[pd.DataFrame, Optional[pd.Series], StandardScaler]:\n",
    "    \"\"\"Preprocess the abalone dataset by one-hot encoding categorical variables and scaling numerical features.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe with all columns.\n",
    "        scaler (Optional[StandardScaler], optional): An existing StandardScaler to use for scaling.\n",
    "            If None, a new scaler will be created and fitted. Defaults to None.\n",
    "        with_target (bool, optional): Whether to separate the target variable 'Rings' from the features. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, Optional[pd.Series], StandardScaler]: A tuple containing the preprocessed dataframe,\n",
    "            the target variable (if with_target is True), and the scaler used.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = onehot(df)\n",
    "\n",
    "    if with_target:\n",
    "        y = df[\"Rings\"]\n",
    "        df = df.drop(\"Rings\", axis=1)\n",
    "    else:\n",
    "        y = None\n",
    "    df, scaler = scale(df, scaler)\n",
    "\n",
    "    return df, y, scaler\n",
    "\n",
    "\n",
    "def train_model(x: pd.DataFrame, y: pd.Series) -> LinearRegression:\n",
    "    \"\"\"Train a Linear Regression model on the provided features and target.\n",
    "\n",
    "    Args:\n",
    "        x (pd.DataFrame): The input features.\n",
    "        y (pd.Series): The target variable.\n",
    "\n",
    "    Returns:\n",
    "        LinearRegression: The trained Linear Regression model.\n",
    "    \"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model: LinearRegression, x: pd.DataFrame, y: pd.Series) -> float:\n",
    "    \"\"\"Evaluate the model using Mean Squared Error (MSE).\n",
    "\n",
    "    Args:\n",
    "        model (LinearRegression): The trained Linear Regression model.\n",
    "        x (pd.DataFrame): The input features.\n",
    "        y (pd.Series): The true target variable.\n",
    "\n",
    "    Returns:\n",
    "        float: The Mean Squared Error of the model's predictions.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(x)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def save_model(model: BaseEstimator, artifacts_path: str) -> None:\n",
    "    \"\"\"Save the trained model to a file.\n",
    "\n",
    "    Args:\n",
    "        model (BaseEstimator): The trained model to save.\n",
    "        artifacts_path (str): The directory path where the model will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(os.path.join(artifacts_path, \"model.pkl\"), \"wb\") as f:\n",
    "        pkl.dump(model, f)\n",
    "\n",
    "\n",
    "def save_scaler(scaler: StandardScaler, artifacts_path: str) -> None:\n",
    "    \"\"\"Save the scaler to a file.\n",
    "\n",
    "    Args:\n",
    "        scaler (StandardScaler): The scaler to save.\n",
    "        artifacts_path (str): The directory path where the scaler will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(os.path.join(artifacts_path, \"scaler.pkl\"), \"wb\") as f:\n",
    "        pkl.dump(scaler, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"abalone-age-experiment\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    x, y, scaler = preprocess_data(df, scaler=None, with_target=True)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    model = train_model(x_train, y_train)\n",
    "    \n",
    "    mse = evaluate_model(model, x_test, y_test)\n",
    "    print(f\"MSE: {mse}\")\n",
    "    artifacts_path = \"../models/\"\n",
    "    save_model(model, artifacts_path)\n",
    "    save_scaler(scaler, artifacts_path)\n",
    "\n",
    "\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "    registered_model = mlflow.register_model(model_uri, \"abalone_regression_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui --host 0.0.0.0 --port 5002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UV XHEC MLOps",
   "language": "python",
   "name": "uv-xhec-mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
