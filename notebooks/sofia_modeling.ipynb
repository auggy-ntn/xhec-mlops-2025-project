{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Abalone Age Prediction - ML Modeling Pipeline\n",
    "\n",
    "# This notebook contains the complete machine learning pipeline for predicting abalone age from physical measurements.\n",
    "\n",
    "# ## Objective\n",
    "# Build a robust ML pipeline with:\n",
    "# - Data preprocessing functions\n",
    "# - Model training with Random Forest\n",
    "# - Comprehensive evaluation metrics\n",
    "# - Prediction pipeline for new data\n",
    "\n",
    "# **Target**: Predict the number of rings (age indicator) from physical measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, Any, Optional\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "\n",
    "# Configure plotting and warnings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"ðŸ¤– Abalone Age Prediction - ML Pipeline\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Inspection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the abalone dataset and perform basic validation.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded dataset\n",
    "    \"\"\"\n",
    "    print(\"ðŸ“‚ Loading dataset...\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"âœ… Dataset loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        \n",
    "        # Basic validation\n",
    "        expected_columns = ['Sex', 'Length', 'Diameter', 'Height', 'Whole weight', \n",
    "                          'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings']\n",
    "        \n",
    "        if list(df.columns) != expected_columns:\n",
    "            print(\"âš ï¸  Warning: Column names don't match expected format\")\n",
    "            print(f\"Found columns: {list(df.columns)}\")\n",
    "            \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ Error: File not found at {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def inspect_data(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Perform comprehensive data inspection.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset to inspect\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, Any]: Inspection summary\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ” Data Inspection Report\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    inspection = {}\n",
    "    \n",
    "    # Basic info\n",
    "    inspection['shape'] = df.shape\n",
    "    inspection['memory_usage'] = df.memory_usage(deep=True).sum() / 1024**2  # MB\n",
    "    \n",
    "    # Missing values\n",
    "    missing = df.isnull().sum()\n",
    "    inspection['missing_values'] = missing[missing > 0].to_dict()\n",
    "    \n",
    "    # Duplicates\n",
    "    inspection['duplicates'] = df.duplicated().sum()\n",
    "    \n",
    "    # Data types\n",
    "    inspection['dtypes'] = df.dtypes.to_dict()\n",
    "    \n",
    "    # Basic statistics for numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    inspection['numerical_summary'] = df[numerical_cols].describe().to_dict()\n",
    "    \n",
    "    # Categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    inspection['categorical_summary'] = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        inspection['categorical_summary'][col] = {\n",
    "            'unique_values': df[col].unique().tolist(),\n",
    "            'value_counts': df[col].value_counts().to_dict()\n",
    "        }\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"ðŸ“Š Shape: {inspection['shape']}\")\n",
    "    print(f\"ðŸ’¾ Memory usage: {inspection['memory_usage']:.2f} MB\")\n",
    "    print(f\"â“ Missing values: {len(inspection['missing_values'])} columns affected\")\n",
    "    print(f\"ðŸ”„ Duplicate rows: {inspection['duplicates']}\")\n",
    "    \n",
    "    if inspection['missing_values']:\n",
    "        print(\"Missing data details:\")\n",
    "        for col, count in inspection['missing_values'].items():\n",
    "            print(f\"  - {col}: {count} missing\")\n",
    "    \n",
    "    return inspection\n",
    "\n",
    "# Load and inspect the data\n",
    "df = load_data('../data/abalone.csv')\n",
    "data_inspection = inspect_data(df)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nðŸ“‹ First 5 rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean the dataset by handling missing values and outliers.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Raw dataset\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned dataset\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ§¹ Cleaning data...\")\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    original_size = len(df_clean)\n",
    "    \n",
    "    # Remove rows with missing values (if any)\n",
    "    if df_clean.isnull().any().any():\n",
    "        df_clean = df_clean.dropna()\n",
    "        print(f\"   Removed {original_size - len(df_clean)} rows with missing values\")\n",
    "    \n",
    "    # Remove duplicate rows\n",
    "    duplicates = df_clean.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        df_clean = df_clean.drop_duplicates()\n",
    "        print(f\"   Removed {duplicates} duplicate rows\")\n",
    "    \n",
    "    # Handle outliers using IQR method for key features\n",
    "    numerical_cols = ['Length', 'Diameter', 'Height', 'Whole weight', \n",
    "                     'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings']\n",
    "    \n",
    "    outliers_removed = 0\n",
    "    for col in numerical_cols:\n",
    "        if col in df_clean.columns:\n",
    "            Q1 = df_clean[col].quantile(0.25)\n",
    "            Q3 = df_clean[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers = df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)]\n",
    "            outliers_removed += len(outliers)\n",
    "            \n",
    "            # Remove extreme outliers (beyond 3 IQR)\n",
    "            extreme_lower = Q1 - 3 * IQR\n",
    "            extreme_upper = Q3 + 3 * IQR\n",
    "            df_clean = df_clean[(df_clean[col] >= extreme_lower) & (df_clean[col] <= extreme_upper)]\n",
    "    \n",
    "    print(f\"   Final dataset size: {len(df_clean)} rows ({original_size - len(df_clean)} removed)\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def encode_categorical_features(df: pd.DataFrame, fit_encoders: bool = True, \n",
    "                               encoders: Dict = None) -> Tuple[pd.DataFrame, Dict]:\n",
    "    \"\"\"\n",
    "    Encode categorical features using appropriate encoding methods.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset with categorical features\n",
    "        fit_encoders (bool): Whether to fit new encoders or use existing ones\n",
    "        encoders (Dict): Pre-fitted encoders (if fit_encoders=False)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, Dict]: Encoded dataset and fitted encoders\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ·ï¸  Encoding categorical features...\")\n",
    "    \n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    if fit_encoders:\n",
    "        encoders = {}\n",
    "        \n",
    "        # Encode Sex column (M, F, I)\n",
    "        if 'Sex' in df_encoded.columns:\n",
    "            le_sex = LabelEncoder()\n",
    "            df_encoded['Sex_encoded'] = le_sex.fit_transform(df_encoded['Sex'])\n",
    "            encoders['Sex'] = le_sex\n",
    "            \n",
    "            # Create dummy variables for better model performance\n",
    "            sex_dummies = pd.get_dummies(df_encoded['Sex'], prefix='Sex')\n",
    "            df_encoded = pd.concat([df_encoded, sex_dummies], axis=1)\n",
    "            \n",
    "            # Drop original Sex column\n",
    "            df_encoded = df_encoded.drop('Sex', axis=1)\n",
    "            \n",
    "            print(f\"   Encoded 'Sex' column: {le_sex.classes_}\")\n",
    "    \n",
    "    else:\n",
    "        # Use existing encoders\n",
    "        if 'Sex' in df_encoded.columns and 'Sex' in encoders:\n",
    "            df_encoded['Sex_encoded'] = encoders['Sex'].transform(df_encoded['Sex'])\n",
    "            \n",
    "            # Create dummy variables\n",
    "            sex_dummies = pd.get_dummies(df_encoded['Sex'], prefix='Sex')\n",
    "            df_encoded = pd.concat([df_encoded, sex_dummies], axis=1)\n",
    "            df_encoded = df_encoded.drop('Sex', axis=1)\n",
    "    \n",
    "    return df_encoded, encoders\n",
    "\n",
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create additional features that might improve model performance.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset with encoded features\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset with engineered features\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ”§ Engineering features...\")\n",
    "    \n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # Create ratio features that might be predictive\n",
    "    if all(col in df_features.columns for col in ['Shucked weight', 'Whole weight']):\n",
    "        # Avoid division by zero and handle small values\n",
    "        whole_weight_safe = df_features['Whole weight'].replace(0, np.nan)\n",
    "        df_features['Shucked_to_Whole_ratio'] = (\n",
    "            df_features['Shucked weight'] / whole_weight_safe\n",
    "        ).fillna(0).replace([np.inf, -np.inf], 0).clip(0, 10)  # Cap extreme values\n",
    "    \n",
    "    if all(col in df_features.columns for col in ['Shell weight', 'Whole weight']):\n",
    "        whole_weight_safe = df_features['Whole weight'].replace(0, np.nan)\n",
    "        df_features['Shell_to_Whole_ratio'] = (\n",
    "            df_features['Shell weight'] / whole_weight_safe\n",
    "        ).fillna(0).replace([np.inf, -np.inf], 0).clip(0, 10)  # Cap extreme values\n",
    "    \n",
    "    if all(col in df_features.columns for col in ['Length', 'Diameter']):\n",
    "        diameter_safe = df_features['Diameter'].replace(0, np.nan)\n",
    "        df_features['Length_to_Diameter_ratio'] = (\n",
    "            df_features['Length'] / diameter_safe\n",
    "        ).fillna(0).replace([np.inf, -np.inf], 0).clip(0, 10)  # Cap extreme values\n",
    "    \n",
    "    # Create volume approximation (Length * Diameter * Height)\n",
    "    if all(col in df_features.columns for col in ['Length', 'Diameter', 'Height']):\n",
    "        df_features['Volume_approx'] = (\n",
    "            df_features['Length'] * df_features['Diameter'] * df_features['Height']\n",
    "        ).replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    \n",
    "    # Create density approximation (Weight / Volume)\n",
    "    if all(col in df_features.columns for col in ['Whole weight', 'Volume_approx']):\n",
    "        volume_safe = df_features['Volume_approx'].replace(0, np.nan)\n",
    "        df_features['Density_approx'] = (\n",
    "            df_features['Whole weight'] / volume_safe\n",
    "        ).fillna(0).replace([np.inf, -np.inf], 0).clip(0, 1000)  # Cap extreme density values\n",
    "    \n",
    "    # Check for and handle any remaining infinite or extremely large values\n",
    "    for col in df_features.select_dtypes(include=[np.number]).columns:\n",
    "        # Replace infinite values with 0\n",
    "        df_features[col] = df_features[col].replace([np.inf, -np.inf], 0)\n",
    "        # Cap extremely large values (greater than 1e6)\n",
    "        df_features[col] = df_features[col].clip(-1e6, 1e6)\n",
    "        # Fill any remaining NaN values with 0\n",
    "        df_features[col] = df_features[col].fillna(0)\n",
    "    \n",
    "    print(f\"   Created {len(df_features.columns) - len(df.columns)} new features\")\n",
    "    print(f\"   All infinite and extreme values handled safely\")\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "def scale_features(X: pd.DataFrame, fit_scaler: bool = True, \n",
    "                  scaler: StandardScaler = None) -> Tuple[pd.DataFrame, StandardScaler]:\n",
    "    \"\"\"\n",
    "    Scale numerical features using StandardScaler.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): Features to scale\n",
    "        fit_scaler (bool): Whether to fit a new scaler or use existing one\n",
    "        scaler (StandardScaler): Pre-fitted scaler (if fit_scaler=False)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, StandardScaler]: Scaled features and fitted scaler\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ“ Scaling features...\")\n",
    "    \n",
    "    # Safety check for infinite or extremely large values before scaling\n",
    "    X_safe = X.copy()\n",
    "    \n",
    "    # Only work with numerical columns\n",
    "    numerical_cols = X_safe.select_dtypes(include=[np.number]).columns\n",
    "    non_numerical_cols = X_safe.select_dtypes(exclude=[np.number]).columns\n",
    "    \n",
    "    if len(non_numerical_cols) > 0:\n",
    "        print(f\"   Warning: Non-numerical columns found: {list(non_numerical_cols)}\")\n",
    "        print(\"   These columns will be excluded from scaling\")\n",
    "    \n",
    "    # Check for and handle problematic values in numerical columns only\n",
    "    for col in numerical_cols:\n",
    "        # Replace infinite values\n",
    "        X_safe[col] = X_safe[col].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Fill NaN values with median\n",
    "        if X_safe[col].isnull().any():\n",
    "            median_val = X_safe[col].median()\n",
    "            if pd.isna(median_val):  # If all values are NaN, use 0\n",
    "                median_val = 0\n",
    "            X_safe[col] = X_safe[col].fillna(median_val)\n",
    "        \n",
    "        # Cap extremely large values\n",
    "        X_safe[col] = X_safe[col].clip(-1e6, 1e6)\n",
    "    \n",
    "    # Verify no infinite or NaN values remain in numerical columns\n",
    "    numerical_data = X_safe[numerical_cols]\n",
    "    if len(numerical_cols) > 0:\n",
    "        if np.any(np.isinf(numerical_data.values)) or np.any(np.isnan(numerical_data.values)):\n",
    "            print(\"   Warning: Found remaining infinite or NaN values, fixing...\")\n",
    "            X_safe[numerical_cols] = X_safe[numerical_cols].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    # Only scale numerical columns\n",
    "    if len(numerical_cols) == 0:\n",
    "        print(\"   Warning: No numerical columns found for scaling!\")\n",
    "        return X_safe, scaler\n",
    "    \n",
    "    # Extract numerical data for scaling\n",
    "    X_numerical = X_safe[numerical_cols]\n",
    "    \n",
    "    if fit_scaler:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled_numerical = scaler.fit_transform(X_numerical)\n",
    "    else:\n",
    "        X_scaled_numerical = scaler.transform(X_numerical)\n",
    "    \n",
    "    # Convert back to DataFrame to preserve column names\n",
    "    X_scaled_df = pd.DataFrame(X_scaled_numerical, columns=numerical_cols, index=X.index)\n",
    "    \n",
    "    # Add back any non-numerical columns (unchanged)\n",
    "    for col in non_numerical_cols:\n",
    "        X_scaled_df[col] = X_safe[col]\n",
    "    \n",
    "    # Reorder columns to match original order\n",
    "    X_scaled_df = X_scaled_df[X.columns]\n",
    "    \n",
    "    print(f\"   Scaled {len(numerical_cols)} numerical features safely\")\n",
    "    if len(non_numerical_cols) > 0:\n",
    "        print(f\"   Kept {len(non_numerical_cols)} non-numerical features unchanged\")\n",
    "    \n",
    "    return X_scaled_df, scaler\n",
    "\n",
    "# Apply preprocessing to the loaded data\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ”„ PREPROCESSING PIPELINE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Clean the data\n",
    "df_clean = clean_data(df)\n",
    "\n",
    "# Encode categorical features\n",
    "df_encoded, encoders = encode_categorical_features(df_clean)\n",
    "\n",
    "# Engineer features\n",
    "df_features = feature_engineering(df_encoded)\n",
    "\n",
    "print(f\"\\nâœ… Preprocessing complete!\")\n",
    "print(f\"   Original columns: {len(df.columns)}\")\n",
    "print(f\"   Final columns: {len(df_features.columns)}\")\n",
    "print(f\"   Final dataset shape: {df_features.shape}\")\n",
    "\n",
    "# Display the processed data\n",
    "print(\"\\nðŸ“‹ Processed data sample:\")\n",
    "display(df_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Data Splitting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_target(df: pd.DataFrame, target_column: str = 'Rings') -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Separate features and target variable.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Processed dataset\n",
    "        target_column (str): Name of the target column\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.Series]: Features and target\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸŽ¯ Preparing features and target ('{target_column}')...\")\n",
    "    \n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset\")\n",
    "    \n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    print(f\"   Features shape: {X.shape}\")\n",
    "    print(f\"   Target shape: {y.shape}\")\n",
    "    print(f\"   Target range: {y.min()} - {y.max()}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def split_data(X: pd.DataFrame, y: pd.Series, \n",
    "              test_size: float = 0.2, \n",
    "              random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Split data into training and testing sets.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): Features\n",
    "        y (pd.Series): Target variable\n",
    "        test_size (float): Proportion of data for testing\n",
    "        random_state (int): Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        Tuple: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“Š Splitting data (test_size={test_size})...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state,\n",
    "        stratify=None  # No stratification for regression\n",
    "    )\n",
    "    \n",
    "    print(f\"   Training set: {X_train.shape[0]} samples\")\n",
    "    print(f\"   Test set: {X_test.shape[0]} samples\")\n",
    "    print(f\"   Training target range: {y_train.min()} - {y_train.max()}\")\n",
    "    print(f\"   Test target range: {y_test.min()} - {y_test.max()}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Prepare features and target\n",
    "X, y = prepare_features_target(df_features, 'Rings')\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "X_train_scaled, feature_scaler = scale_features(X_train, fit_scaler=True)\n",
    "X_test_scaled, _ = scale_features(X_test, fit_scaler=False, scaler=feature_scaler)\n",
    "\n",
    "print(f\"\\nâœ… Data preparation complete!\")\n",
    "print(f\"   Training features: {X_train_scaled.shape}\")\n",
    "print(f\"   Test features: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train: pd.DataFrame, y_train: pd.Series,\n",
    "                       hyperparameter_tuning: bool = True,\n",
    "                       cv_folds: int = 5,\n",
    "                       random_state: int = 42) -> Tuple[RandomForestRegressor, Dict]:\n",
    "    \"\"\"\n",
    "    Train a Random Forest model with optional hyperparameter tuning.\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training features\n",
    "        y_train (pd.Series): Training target\n",
    "        hyperparameter_tuning (bool): Whether to perform hyperparameter tuning\n",
    "        cv_folds (int): Number of cross-validation folds\n",
    "        random_state (int): Random seed\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[RandomForestRegressor, Dict]: Trained model and training info\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸŒ² Training Random Forest model...\")\n",
    "    \n",
    "    training_info = {}\n",
    "    \n",
    "    if hyperparameter_tuning:\n",
    "        print(\"   Performing hyperparameter tuning...\")\n",
    "        \n",
    "        # Define parameter grid\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['sqrt', 'log2']\n",
    "        }\n",
    "        \n",
    "        # Create base model\n",
    "        rf_base = RandomForestRegressor(random_state=random_state)\n",
    "        \n",
    "        # Perform grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            rf_base, \n",
    "            param_grid, \n",
    "            cv=cv_folds,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get best model\n",
    "        model = grid_search.best_estimator_\n",
    "        training_info['best_params'] = grid_search.best_params_\n",
    "        training_info['best_cv_score'] = -grid_search.best_score_\n",
    "        training_info['cv_results'] = grid_search.cv_results_\n",
    "        \n",
    "        print(f\"   Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"   Best CV RMSE: {np.sqrt(-grid_search.best_score_):.4f}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"   Training with default parameters...\")\n",
    "        \n",
    "        # Use default parameters with some reasonable settings\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=20,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            max_features='sqrt',\n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Perform cross-validation to get performance estimate\n",
    "        cv_scores = cross_val_score(\n",
    "            model, X_train, y_train, \n",
    "            cv=cv_folds, \n",
    "            scoring='neg_mean_squared_error'\n",
    "        )\n",
    "        \n",
    "        training_info['cv_scores'] = cv_scores\n",
    "        training_info['mean_cv_score'] = -cv_scores.mean()\n",
    "        training_info['std_cv_score'] = cv_scores.std()\n",
    "        \n",
    "        print(f\"   CV RMSE: {np.sqrt(-cv_scores.mean()):.4f} (+/- {np.sqrt(cv_scores.std() * 2):.4f})\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    training_info['feature_importance'] = feature_importance\n",
    "    training_info['training_samples'] = len(X_train)\n",
    "    training_info['n_features'] = X_train.shape[1]\n",
    "    \n",
    "    print(f\"   Model trained successfully!\")\n",
    "    print(f\"   Training samples: {len(X_train)}\")\n",
    "    print(f\"   Features used: {X_train.shape[1]}\")\n",
    "    \n",
    "    return model, training_info\n",
    "\n",
    "def save_model_and_artifacts(model: RandomForestRegressor, \n",
    "                           scaler: StandardScaler,\n",
    "                           encoders: Dict,\n",
    "                           training_info: Dict,\n",
    "                           model_dir: str = '../models') -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Save the trained model and all preprocessing artifacts.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        scaler: Fitted feature scaler\n",
    "        encoders: Fitted encoders\n",
    "        training_info: Training information\n",
    "        model_dir: Directory to save models\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, str]: Paths where artifacts were saved\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ’¾ Saving model and artifacts to '{model_dir}'...\")\n",
    "    \n",
    "    # Create model directory if it doesn't exist\n",
    "    Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    paths = {}\n",
    "    \n",
    "    # Save model\n",
    "    model_path = Path(model_dir) / 'random_forest_model.joblib'\n",
    "    joblib.dump(model, model_path)\n",
    "    paths['model'] = str(model_path)\n",
    "    \n",
    "    # Save scaler\n",
    "    scaler_path = Path(model_dir) / 'feature_scaler.joblib'\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    paths['scaler'] = str(scaler_path)\n",
    "    \n",
    "    # Save encoders\n",
    "    encoders_path = Path(model_dir) / 'encoders.joblib'\n",
    "    joblib.dump(encoders, encoders_path)\n",
    "    paths['encoders'] = str(encoders_path)\n",
    "    \n",
    "    # Save training info\n",
    "    training_info_path = Path(model_dir) / 'training_info.joblib'\n",
    "    joblib.dump(training_info, training_info_path)\n",
    "    paths['training_info'] = str(training_info_path)\n",
    "    \n",
    "    print(\"   âœ… All artifacts saved successfully!\")\n",
    "    for artifact, path in paths.items():\n",
    "        print(f\"      {artifact}: {path}\")\n",
    "    \n",
    "    return paths\n",
    "\n",
    "# Train the model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ¤– MODEL TRAINING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Train Random Forest with hyperparameter tuning\n",
    "model, training_info = train_random_forest(\n",
    "    X_train_scaled, y_train,\n",
    "    hyperparameter_tuning=True,  # Set to False for faster training\n",
    "    cv_folds=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Save model and artifacts\n",
    "saved_paths = save_model_and_artifacts(\n",
    "    model=model,\n",
    "    scaler=feature_scaler,\n",
    "    encoders=encoders,\n",
    "    training_info=training_info,\n",
    "    model_dir='../models'\n",
    ")\n",
    "\n",
    "# Display top feature importances\n",
    "print(f\"\\nðŸ” Top 10 Feature Importances:\")\n",
    "top_features = training_info['feature_importance'].head(10)\n",
    "display(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: RandomForestRegressor, \n",
    "                  X_test: pd.DataFrame, \n",
    "                  y_test: pd.Series,\n",
    "                  X_train: pd.DataFrame = None,\n",
    "                  y_train: pd.Series = None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate model performance with comprehensive metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_test: Test features\n",
    "        y_test: Test target\n",
    "        X_train: Training features (optional, for training metrics)\n",
    "        y_train: Training target (optional, for training metrics)\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, float]: Evaluation metrics\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ“Š Evaluating model performance...\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Calculate test metrics\n",
    "    test_metrics = {\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "        'test_mae': mean_absolute_error(y_test, y_pred_test),\n",
    "        'test_r2': r2_score(y_test, y_pred_test)\n",
    "    }\n",
    "    \n",
    "    # Calculate training metrics if training data provided\n",
    "    if X_train is not None and y_train is not None:\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        train_metrics = {\n",
    "            'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'train_mae': mean_absolute_error(y_train, y_pred_train),\n",
    "            'train_r2': r2_score(y_train, y_pred_train)\n",
    "        }\n",
    "        test_metrics.update(train_metrics)\n",
    "        \n",
    "        # Calculate overfitting indicators\n",
    "        test_metrics['overfitting_rmse'] = train_metrics['train_rmse'] - test_metrics['test_rmse']\n",
    "        test_metrics['overfitting_r2'] = train_metrics['train_r2'] - test_metrics['test_r2']\n",
    "    \n",
    "    # Print results\n",
    "    print(\"   Test Performance:\")\n",
    "    print(f\"      RMSE: {test_metrics['test_rmse']:.4f}\")\n",
    "    print(f\"      MAE:  {test_metrics['test_mae']:.4f}\")\n",
    "    print(f\"      RÂ²:   {test_metrics['test_r2']:.4f}\")\n",
    "    \n",
    "    if 'train_rmse' in test_metrics:\n",
    "        print(\"   Training Performance:\")\n",
    "        print(f\"      RMSE: {test_metrics['train_rmse']:.4f}\")\n",
    "        print(f\"      MAE:  {test_metrics['train_mae']:.4f}\")\n",
    "        print(f\"      RÂ²:   {test_metrics['train_r2']:.4f}\")\n",
    "        \n",
    "        print(\"   Overfitting Analysis:\")\n",
    "        print(f\"      RMSE difference: {test_metrics['overfitting_rmse']:.4f}\")\n",
    "        print(f\"      RÂ² difference:   {test_metrics['overfitting_r2']:.4f}\")\n",
    "    \n",
    "    return test_metrics\n",
    "\n",
    "def plot_evaluation_charts(model: RandomForestRegressor,\n",
    "                          X_test: pd.DataFrame,\n",
    "                          y_test: pd.Series,\n",
    "                          X_train: pd.DataFrame = None,\n",
    "                          y_train: pd.Series = None,\n",
    "                          feature_names: list = None):\n",
    "    \"\"\"\n",
    "    Create comprehensive evaluation visualizations.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_test: Test features\n",
    "        y_test: Test target\n",
    "        X_train: Training features (optional)\n",
    "        y_train: Training target (optional)\n",
    "        feature_names: List of feature names for importance plot\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ“ˆ Creating evaluation visualizations...\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Model Evaluation Dashboard', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Actual vs Predicted scatter plot\n",
    "    axes[0, 0].scatter(y_test, y_pred_test, alpha=0.6, color='blue')\n",
    "    axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[0, 0].set_xlabel('Actual Rings')\n",
    "    axes[0, 0].set_ylabel('Predicted Rings')\n",
    "    axes[0, 0].set_title('Actual vs Predicted (Test Set)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add RÂ² to the plot\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    axes[0, 0].text(0.05, 0.95, f'RÂ² = {r2:.3f}', transform=axes[0, 0].transAxes, \n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 2. Residuals plot\n",
    "    residuals = y_test - y_pred_test\n",
    "    axes[0, 1].scatter(y_pred_test, residuals, alpha=0.6, color='green')\n",
    "    axes[0, 1].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[0, 1].set_xlabel('Predicted Rings')\n",
    "    axes[0, 1].set_ylabel('Residuals')\n",
    "    axes[0, 1].set_title('Residuals Plot')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residuals histogram\n",
    "    axes[0, 2].hist(residuals, bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "    axes[0, 2].axvline(residuals.mean(), color='red', linestyle='--', \n",
    "                      label=f'Mean: {residuals.mean():.3f}')\n",
    "    axes[0, 2].set_xlabel('Residuals')\n",
    "    axes[0, 2].set_ylabel('Frequency')\n",
    "    axes[0, 2].set_title('Residuals Distribution')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Feature importance (top 15)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_names = feature_names or [f'Feature_{i}' for i in range(len(model.feature_importances_))]\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=True).tail(15)\n",
    "        \n",
    "        axes[1, 0].barh(range(len(importance_df)), importance_df['importance'], color='orange')\n",
    "        axes[1, 0].set_yticks(range(len(importance_df)))\n",
    "        axes[1, 0].set_yticklabels(importance_df['feature'])\n",
    "        axes[1, 0].set_xlabel('Importance')\n",
    "        axes[1, 0].set_title('Top 15 Feature Importances')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Prediction error distribution by target range\n",
    "    bins = pd.cut(y_test, bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "    error_by_range = pd.DataFrame({\n",
    "        'Range': bins,\n",
    "        'Absolute_Error': np.abs(residuals)\n",
    "    })\n",
    "    \n",
    "    error_summary = error_by_range.groupby('Range')['Absolute_Error'].mean()\n",
    "    axes[1, 1].bar(error_summary.index, error_summary.values, color='lightcoral')\n",
    "    axes[1, 1].set_xlabel('Target Value Range')\n",
    "    axes[1, 1].set_ylabel('Mean Absolute Error')\n",
    "    axes[1, 1].set_title('Prediction Error by Target Range')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Training vs Test comparison (if training data provided)\n",
    "    if X_train is not None and y_train is not None:\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        \n",
    "        # Calculate metrics for both sets\n",
    "        train_r2 = r2_score(y_train, y_pred_train)\n",
    "        test_r2 = r2_score(y_test, y_pred_test)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        \n",
    "        metrics = ['RÂ²', 'RMSE']\n",
    "        train_scores = [train_r2, train_rmse]\n",
    "        test_scores = [test_r2, test_rmse]\n",
    "        \n",
    "        x = np.arange(len(metrics))\n",
    "        width = 0.35\n",
    "        \n",
    "        axes[1, 2].bar(x - width/2, train_scores, width, label='Training', color='skyblue')\n",
    "        axes[1, 2].bar(x + width/2, test_scores, width, label='Test', color='lightgreen')\n",
    "        axes[1, 2].set_xlabel('Metrics')\n",
    "        axes[1, 2].set_ylabel('Score')\n",
    "        axes[1, 2].set_title('Training vs Test Performance')\n",
    "        axes[1, 2].set_xticks(x)\n",
    "        axes[1, 2].set_xticklabels(metrics)\n",
    "        axes[1, 2].legend()\n",
    "        axes[1, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, (train, test) in enumerate(zip(train_scores, test_scores)):\n",
    "            axes[1, 2].text(i - width/2, train + 0.01, f'{train:.3f}', \n",
    "                           ha='center', va='bottom', fontsize=9)\n",
    "            axes[1, 2].text(i + width/2, test + 0.01, f'{test:.3f}', \n",
    "                           ha='center', va='bottom', fontsize=9)\n",
    "    else:\n",
    "        # If no training data, show prediction confidence intervals\n",
    "        axes[1, 2].text(0.5, 0.5, 'Training data not provided\\nfor comparison', \n",
    "                        ha='center', va='center', transform=axes[1, 2].transAxes,\n",
    "                        fontsize=12)\n",
    "        axes[1, 2].set_title('Training vs Test Comparison')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def calculate_feature_importance_permutation(model: RandomForestRegressor,\n",
    "                                           X_test: pd.DataFrame,\n",
    "                                           y_test: pd.Series,\n",
    "                                           random_state: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate permutation feature importance for more reliable importance estimates.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_test: Test features\n",
    "        y_test: Test target\n",
    "        random_state: Random seed\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Permutation feature importances\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ”€ Calculating permutation feature importances...\")\n",
    "    \n",
    "    # Calculate permutation importance\n",
    "    perm_importance = permutation_importance(\n",
    "        model, X_test, y_test, \n",
    "        n_repeats=10,\n",
    "        random_state=random_state,\n",
    "        scoring='neg_mean_squared_error'\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame\n",
    "    perm_imp_df = pd.DataFrame({\n",
    "        'feature': X_test.columns,\n",
    "        'importance_mean': perm_importance.importances_mean,\n",
    "        'importance_std': perm_importance.importances_std\n",
    "    }).sort_values('importance_mean', ascending=False)\n",
    "    \n",
    "    print(f\"   Calculated for {len(X_test.columns)} features\")\n",
    "    \n",
    "    return perm_imp_df\n",
    "\n",
    "# Evaluate the trained model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ“Š MODEL EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Comprehensive evaluation\n",
    "evaluation_metrics = evaluate_model(\n",
    "    model=model,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train\n",
    ")\n",
    "\n",
    "# Create evaluation visualizations\n",
    "plot_evaluation_charts(\n",
    "    model=model,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    feature_names=X_train_scaled.columns.tolist()\n",
    ")\n",
    "\n",
    "# Calculate permutation importance\n",
    "perm_importance = calculate_feature_importance_permutation(\n",
    "    model=model,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ” Top 10 Permutation Feature Importances:\")\n",
    "display(perm_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6. Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_artifacts(model_dir: str = '../models') -> Tuple[RandomForestRegressor, StandardScaler, Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Load trained model and all preprocessing artifacts.\n",
    "    \n",
    "    Args:\n",
    "        model_dir (str): Directory containing saved models\n",
    "        \n",
    "    Returns:\n",
    "        Tuple: Loaded model, scaler, encoders, and training info\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ“‚ Loading model artifacts from '{model_dir}'...\")\n",
    "    \n",
    "    model_path = Path(model_dir) / 'random_forest_model.joblib'\n",
    "    scaler_path = Path(model_dir) / 'feature_scaler.joblib'\n",
    "    encoders_path = Path(model_dir) / 'encoders.joblib'\n",
    "    training_info_path = Path(model_dir) / 'training_info.joblib'\n",
    "    \n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        encoders = joblib.load(encoders_path)\n",
    "        training_info = joblib.load(training_info_path)\n",
    "        \n",
    "        print(\"   âœ… All artifacts loaded successfully!\")\n",
    "        \n",
    "        return model, scaler, encoders, training_info\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"   âŒ Error: Could not find model artifacts: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error loading artifacts: {e}\")\n",
    "        raise\n",
    "\n",
    "def preprocess_new_data(data: pd.DataFrame, \n",
    "                       encoders: Dict, \n",
    "                       scaler: StandardScaler) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess new data for prediction using fitted artifacts.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): New data to preprocess\n",
    "        encoders (Dict): Fitted encoders\n",
    "        scaler (StandardScaler): Fitted scaler\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed data ready for prediction\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”§ Preprocessing new data for prediction...\")\n",
    "    \n",
    "    data_processed = data.copy()\n",
    "    \n",
    "    # Apply the same cleaning as training data (but don't remove outliers for new data)\n",
    "    # Just handle missing values\n",
    "    if data_processed.isnull().any().any():\n",
    "        print(\"   Warning: Found missing values in new data\")\n",
    "        # For prediction, you might want to handle this differently\n",
    "        data_processed = data_processed.fillna(data_processed.median())\n",
    "    \n",
    "    # Apply categorical encoding\n",
    "    if 'Sex' in data_processed.columns and 'Sex' in encoders:\n",
    "        # Encode Sex column\n",
    "        data_processed['Sex_encoded'] = encoders['Sex'].transform(data_processed['Sex'])\n",
    "        \n",
    "        # Create dummy variables\n",
    "        sex_dummies = pd.get_dummies(data_processed['Sex'], prefix='Sex')\n",
    "        data_processed = pd.concat([data_processed, sex_dummies], axis=1)\n",
    "        data_processed = data_processed.drop('Sex', axis=1)\n",
    "    \n",
    "    # Apply feature engineering (same as training)\n",
    "    data_processed = feature_engineering(data_processed)\n",
    "    \n",
    "    # Remove target column if it exists (for prediction on new data)\n",
    "    if 'Rings' in data_processed.columns:\n",
    "        data_processed = data_processed.drop('Rings', axis=1)\n",
    "    \n",
    "    # Apply scaling\n",
    "    data_scaled, _ = scale_features(data_processed, fit_scaler=False, scaler=scaler)\n",
    "    \n",
    "    print(f\"   Preprocessed {len(data_processed)} samples with {len(data_processed.columns)} features\")\n",
    "    \n",
    "    return data_scaled\n",
    "\n",
    "def predict_abalone_age(model: RandomForestRegressor,\n",
    "                       data: pd.DataFrame,\n",
    "                       encoders: Dict,\n",
    "                       scaler: StandardScaler,\n",
    "                       return_confidence: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    Make predictions on new abalone data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        data: New data (raw format)\n",
    "        encoders: Fitted encoders\n",
    "        scaler: Fitted scaler\n",
    "        return_confidence: Whether to return prediction intervals\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Predictions and metadata\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ”® Making predictions for {len(data)} samples...\")\n",
    "    \n",
    "    # Preprocess the data\n",
    "    data_processed = preprocess_new_data(data, encoders, scaler)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(data_processed)\n",
    "    \n",
    "    # Calculate prediction intervals if requested\n",
    "    prediction_results = {\n",
    "        'predictions': predictions,\n",
    "        'num_samples': len(data),\n",
    "        'features_used': list(data_processed.columns)\n",
    "    }\n",
    "    \n",
    "    if return_confidence and hasattr(model, 'estimators_'):\n",
    "        # Calculate prediction intervals using individual trees\n",
    "        tree_predictions = np.array([tree.predict(data_processed) for tree in model.estimators_])\n",
    "        \n",
    "        # Calculate confidence intervals (e.g., 95%)\n",
    "        lower_percentile = np.percentile(tree_predictions, 2.5, axis=0)\n",
    "        upper_percentile = np.percentile(tree_predictions, 97.5, axis=0)\n",
    "        \n",
    "        prediction_results.update({\n",
    "            'confidence_lower': lower_percentile,\n",
    "            'confidence_upper': upper_percentile,\n",
    "            'confidence_width': upper_percentile - lower_percentile\n",
    "        })\n",
    "    \n",
    "    # Convert to age in years (rings + 1.5)\n",
    "    age_predictions = predictions + 1.5\n",
    "    prediction_results['age_years'] = age_predictions\n",
    "    \n",
    "    print(f\"   âœ… Predictions complete!\")\n",
    "    print(f\"   Predicted rings range: {predictions.min():.1f} - {predictions.max():.1f}\")\n",
    "    print(f\"   Predicted age range: {age_predictions.min():.1f} - {age_predictions.max():.1f} years\")\n",
    "    \n",
    "    return prediction_results\n",
    "\n",
    "def create_sample_prediction_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create sample data for demonstration of prediction pipeline.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Sample abalone data\n",
    "    \"\"\"\n",
    "    sample_data = pd.DataFrame({\n",
    "        'Sex': ['M', 'F', 'I'],\n",
    "        'Length': [0.455, 0.53, 0.33],\n",
    "        'Diameter': [0.365, 0.42, 0.255],\n",
    "        'Height': [0.095, 0.135, 0.08],\n",
    "        'Whole weight': [0.514, 0.677, 0.205],\n",
    "        'Shucked weight': [0.2245, 0.2565, 0.0895],\n",
    "        'Viscera weight': [0.101, 0.1415, 0.0395],\n",
    "        'Shell weight': [0.15, 0.21, 0.055]\n",
    "    })\n",
    "    \n",
    "    return sample_data\n",
    "\n",
    "# Demonstrate prediction pipeline\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ”® PREDICTION PIPELINE DEMO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create sample data for prediction\n",
    "sample_data = create_sample_prediction_data()\n",
    "print(\"Sample data for prediction:\")\n",
    "display(sample_data)\n",
    "\n",
    "# Make predictions\n",
    "prediction_results = predict_abalone_age(\n",
    "    model=model,\n",
    "    data=sample_data,\n",
    "    encoders=encoders,\n",
    "    scaler=feature_scaler,\n",
    "    return_confidence=True\n",
    ")\n",
    "\n",
    "# Display results\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Sex': sample_data['Sex'],\n",
    "    'Length': sample_data['Length'],\n",
    "    'Predicted_Rings': prediction_results['predictions'],\n",
    "    'Predicted_Age_Years': prediction_results['age_years'],\n",
    "    'Confidence_Lower': prediction_results.get('confidence_lower', [None]*len(sample_data)),\n",
    "    'Confidence_Upper': prediction_results.get('confidence_upper', [None]*len(sample_data))\n",
    "})\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Prediction Results:\")\n",
    "display(predictions_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 7. Complete ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_ml_pipeline(data_path: str,\n",
    "                        model_dir: str = '../models',\n",
    "                        test_size: float = 0.2,\n",
    "                        hyperparameter_tuning: bool = True,\n",
    "                        save_artifacts: bool = True,\n",
    "                        random_state: int = 42) -> Dict:\n",
    "    \"\"\"\n",
    "    Complete end-to-end ML pipeline for abalone age prediction.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Path to the dataset\n",
    "        model_dir (str): Directory to save models\n",
    "        test_size (float): Proportion for test set\n",
    "        hyperparameter_tuning (bool): Whether to tune hyperparameters\n",
    "        save_artifacts (bool): Whether to save model artifacts\n",
    "        random_state (int): Random seed\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Pipeline results and artifacts\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ STARTING COMPLETE ML PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    pipeline_results = {}\n",
    "    \n",
    "    try:\n",
    "        # 1. Load and inspect data\n",
    "        print(\"\\nðŸ“Š STEP 1: Data Loading & Inspection\")\n",
    "        df = load_data(data_path)\n",
    "        data_inspection = inspect_data(df)\n",
    "        pipeline_results['data_inspection'] = data_inspection\n",
    "        \n",
    "        # 2. Data preprocessing\n",
    "        print(\"\\nðŸ”§ STEP 2: Data Preprocessing\")\n",
    "        df_clean = clean_data(df)\n",
    "        df_encoded, encoders = encode_categorical_features(df_clean)\n",
    "        df_features = feature_engineering(df_encoded)\n",
    "        \n",
    "        # 3. Prepare features and split data\n",
    "        print(\"\\nðŸ“Š STEP 3: Feature Preparation & Data Splitting\")\n",
    "        X, y = prepare_features_target(df_features, 'Rings')\n",
    "        X_train, X_test, y_train, y_test = split_data(X, y, test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        # 4. Scale features\n",
    "        print(\"\\nðŸ“ STEP 4: Feature Scaling\")\n",
    "        X_train_scaled, feature_scaler = scale_features(X_train, fit_scaler=True)\n",
    "        X_test_scaled, _ = scale_features(X_test, fit_scaler=False, scaler=feature_scaler)\n",
    "        \n",
    "        # 5. Train model\n",
    "        print(\"\\nðŸ¤– STEP 5: Model Training\")\n",
    "        model, training_info = train_random_forest(\n",
    "            X_train_scaled, y_train,\n",
    "            hyperparameter_tuning=hyperparameter_tuning,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # 6. Evaluate model\n",
    "        print(\"\\nðŸ“ˆ STEP 6: Model Evaluation\")\n",
    "        evaluation_metrics = evaluate_model(\n",
    "            model=model,\n",
    "            X_test=X_test_scaled,\n",
    "            y_test=y_test,\n",
    "            X_train=X_train_scaled,\n",
    "            y_train=y_train\n",
    "        )\n",
    "        \n",
    "        # 7. Save artifacts if requested\n",
    "        if save_artifacts:\n",
    "            print(\"\\nðŸ’¾ STEP 7: Saving Artifacts\")\n",
    "            saved_paths = save_model_and_artifacts(\n",
    "                model=model,\n",
    "                scaler=feature_scaler,\n",
    "                encoders=encoders,\n",
    "                training_info=training_info,\n",
    "                model_dir=model_dir\n",
    "            )\n",
    "            pipeline_results['saved_paths'] = saved_paths\n",
    "        \n",
    "        # Compile results\n",
    "        pipeline_results.update({\n",
    "            'model': model,\n",
    "            'scaler': feature_scaler,\n",
    "            'encoders': encoders,\n",
    "            'training_info': training_info,\n",
    "            'evaluation_metrics': evaluation_metrics,\n",
    "            'test_predictions': model.predict(X_test_scaled),\n",
    "            'feature_names': X_train_scaled.columns.tolist(),\n",
    "            'data_shapes': {\n",
    "                'original': df.shape,\n",
    "                'processed': df_features.shape,\n",
    "                'train': X_train_scaled.shape,\n",
    "                'test': X_test_scaled.shape\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        print(\"\\nðŸŽ‰ PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"ðŸ“Š Final Results Summary:\")\n",
    "        print(f\"   â€¢ Dataset: {df.shape[0]} samples, {df.shape[1]} original features\")\n",
    "        print(f\"   â€¢ Processed: {df_features.shape[1]} features after engineering\")\n",
    "        print(f\"   â€¢ Model: Random Forest Regressor\")\n",
    "        print(f\"   â€¢ Test RMSE: {evaluation_metrics['test_rmse']:.4f}\")\n",
    "        print(f\"   â€¢ Test RÂ²: {evaluation_metrics['test_r2']:.4f}\")\n",
    "        print(f\"   â€¢ Test MAE: {evaluation_metrics['test_mae']:.4f}\")\n",
    "        \n",
    "        return pipeline_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ PIPELINE FAILED: {str(e)}\")\n",
    "        print(\"Please check the error and try again.\")\n",
    "        raise\n",
    "\n",
    "def pipeline_summary_report(pipeline_results: Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a summary report of the pipeline results.\n",
    "    \n",
    "    Args:\n",
    "        pipeline_results (Dict): Results from complete_ml_pipeline\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Summary report\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ“‹ PIPELINE SUMMARY REPORT\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    metrics = pipeline_results['evaluation_metrics']\n",
    "    training_info = pipeline_results['training_info']\n",
    "    data_shapes = pipeline_results['data_shapes']\n",
    "    \n",
    "    # Create summary data\n",
    "    summary_data = [\n",
    "        ['Dataset', 'Original Samples', data_shapes['original'][0]],\n",
    "        ['Dataset', 'Original Features', data_shapes['original'][1]],\n",
    "        ['Dataset', 'Processed Features', data_shapes['processed'][1]],\n",
    "        ['Split', 'Training Samples', data_shapes['train'][0]],\n",
    "        ['Split', 'Test Samples', data_shapes['test'][0]],\n",
    "        ['Model', 'Type', 'Random Forest'],\n",
    "        ['Model', 'Training Features', training_info['n_features']],\n",
    "        ['Performance', 'Test RMSE', f\"{metrics['test_rmse']:.4f}\"],\n",
    "        ['Performance', 'Test MAE', f\"{metrics['test_mae']:.4f}\"],\n",
    "        ['Performance', 'Test RÂ²', f\"{metrics['test_r2']:.4f}\"],\n",
    "    ]\n",
    "    \n",
    "    if 'train_rmse' in metrics:\n",
    "        summary_data.extend([\n",
    "            ['Performance', 'Train RMSE', f\"{metrics['train_rmse']:.4f}\"],\n",
    "            ['Performance', 'Train RÂ²', f\"{metrics['train_r2']:.4f}\"],\n",
    "            ['Overfitting', 'RMSE Difference', f\"{metrics['overfitting_rmse']:.4f}\"],\n",
    "            ['Overfitting', 'RÂ² Difference', f\"{metrics['overfitting_r2']:.4f}\"]\n",
    "        ])\n",
    "    \n",
    "    # Top features\n",
    "    top_features = training_info['feature_importance'].head(3)\n",
    "    for i, (_, row) in enumerate(top_features.iterrows()):\n",
    "        summary_data.append(['Top Features', f'#{i+1} {row[\"feature\"]}', f'{row[\"importance\"]:.4f}'])\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data, columns=['Category', 'Metric', 'Value'])\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Run the complete pipeline (optional - can be run manually)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ¯ COMPLETE ML PIPELINE DEMONSTRATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Uncomment the lines below to run the complete pipeline\n",
    "# This is optional since we already ran parts of it above\n",
    "\n",
    "pipeline_results_demo = {\n",
    "    'model': model,\n",
    "    'scaler': feature_scaler,\n",
    "    'encoders': encoders,\n",
    "    'training_info': training_info,\n",
    "    'evaluation_metrics': evaluation_metrics,\n",
    "    'test_predictions': model.predict(X_test_scaled),\n",
    "    'feature_names': X_train_scaled.columns.tolist(),\n",
    "    'data_shapes': {\n",
    "        'original': df.shape,\n",
    "        'processed': df_features.shape,\n",
    "        'train': X_train_scaled.shape,\n",
    "        'test': X_test_scaled.shape\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate summary report\n",
    "summary_report = pipeline_summary_report(pipeline_results_demo)\n",
    "print(\"\\nðŸ“Š Final Pipeline Summary:\")\n",
    "display(summary_report)\n",
    "\n",
    "print(f\"\\nðŸŽ‰ ML Pipeline Complete!\")\n",
    "print(f\"Model saved and ready for deployment!\")\n",
    "\n",
    "# Example of running the complete pipeline from scratch:\n",
    "print(f\"\\nðŸ’¡ To run the complete pipeline from scratch:\")\n",
    "print(f\"   results = complete_ml_pipeline('../data/abalone.csv')\")\n",
    "print(f\"   summary = pipeline_summary_report(results)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
