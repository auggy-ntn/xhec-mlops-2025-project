{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you should implement a first version of a working machine learning model to predict the age of an Abalone.\n",
    "\n",
    "A few guidelines:\n",
    "- The model does not have to be complex. A simple linear regression model is enough.\n",
    "- You should use MLflow to track your experiments. You can use the MLflow UI to compare your experiments.\n",
    "- Do not push any MLflow data to the repository. Only the code to run the experiments is interesting and should be pushed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the parent directory to sys.path for module imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional, Tuple\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from mlflow import MlflowClient\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from src.modelling.config import NUMERICAL_COLS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "# Display available experiments\n",
    "experiments = client.search_experiments()\n",
    "for exp in experiments:\n",
    "    print(f\"Experiment ID: {exp.experiment_id}, Name: {exp.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/abalone.csv\")\n",
    "# df_y = df['Rings']\n",
    "# df = df.drop('Rings', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions for the abalone dataset.\n",
    "\n",
    "\n",
    "def create_preprocessor() -> ColumnTransformer:\n",
    "    \"\"\"Create a preprocessor that handles both one-hot encoding and scaling.\n",
    "\n",
    "    Returns:\n",
    "        ColumnTransformer: A preprocessor that one-hot encodes 'Sex' and scales numerical features.\n",
    "    \"\"\"\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"onehot\", OneHotEncoder(drop=\"first\", sparse_output=False), [\"Sex\"]),\n",
    "            (\"scaler\", StandardScaler(), NUMERICAL_COLS),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def preprocess_data(\n",
    "    df: pd.DataFrame,\n",
    "    preprocessor: Optional[ColumnTransformer] = None,\n",
    "    with_target: bool = True,\n",
    ") -> Tuple[pd.DataFrame, Optional[pd.Series], ColumnTransformer]:\n",
    "    \"\"\"Preprocess the abalone dataset using a unified preprocessor.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe with all columns.\n",
    "        preprocessor (Optional[ColumnTransformer], optional): An existing preprocessor to use.\n",
    "            If None, a new preprocessor will be created and fitted. Defaults to None.\n",
    "        with_target (bool, optional): Whether to separate the target variable 'Rings' from the features. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, Optional[pd.Series], ColumnTransformer]: A tuple containing the preprocessed dataframe,\n",
    "            the target variable (if with_target is True), and the preprocessor used.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.rename(columns=lambda x: x.replace(\" \", \"_\"))\n",
    "\n",
    "    if with_target:\n",
    "        y = df[\"Rings\"]\n",
    "        X = df.drop(\"Rings\", axis=1)\n",
    "    else:\n",
    "        y = None\n",
    "        X = df\n",
    "\n",
    "    if preprocessor is None:\n",
    "        preprocessor = create_preprocessor()\n",
    "        X_processed = preprocessor.fit_transform(X)\n",
    "    else:\n",
    "        X_processed = preprocessor.transform(X)\n",
    "\n",
    "    # Get feature names after transformation\n",
    "    feature_names = []\n",
    "    for name, transformer, columns in preprocessor.transformers_:\n",
    "        if name == \"onehot\":\n",
    "            feature_names.extend(transformer.get_feature_names_out(columns))\n",
    "        elif name == \"scaler\":\n",
    "            feature_names.extend(columns)\n",
    "        elif name != \"remainder\":\n",
    "            feature_names.extend(columns)\n",
    "\n",
    "    X_processed_df = pd.DataFrame(X_processed, columns=feature_names, index=X.index)\n",
    "\n",
    "    return X_processed_df, y, preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x: pd.DataFrame, y: pd.Series) -> LinearRegression:\n",
    "    \"\"\"Train a Linear Regression model on the provided features and target.\n",
    "\n",
    "    Args:\n",
    "        x (pd.DataFrame): The input features.\n",
    "        y (pd.Series): The target variable.\n",
    "\n",
    "    Returns:\n",
    "        LinearRegression: The trained Linear Regression model.\n",
    "    \"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model: LinearRegression, x: pd.DataFrame, y: pd.Series) -> float:\n",
    "    \"\"\"Evaluate the model using Mean Squared Error (MSE).\n",
    "\n",
    "    Args:\n",
    "        model (LinearRegression): The trained Linear Regression model.\n",
    "        x (pd.DataFrame): The input features.\n",
    "        y (pd.Series): The true target variable.\n",
    "\n",
    "    Returns:\n",
    "        float: The Mean Squared Error of the model's predictions.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(x)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle(obj: Any, file_path: str) -> None:\n",
    "    \"\"\"Save an object to a specified file path in pickle format.\n",
    "\n",
    "    Args:\n",
    "        obj (object): The object to pickle.\n",
    "        file_path (str): The file path where the object will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    # Create parent directories if they don't exist\n",
    "    file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with file_path.open(\"wb\") as f:\n",
    "        pkl.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"abalone-age-experiment\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    x, y, preprocessor = preprocess_data(df, preprocessor=None, with_target=True)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    model = train_model(x_train, y_train)\n",
    "\n",
    "    mse = evaluate_model(model, x_test, y_test)\n",
    "    print(f\"MSE: {mse}\")\n",
    "    artifacts_path = Path(\"../models/\")\n",
    "    save_to_pickle(model, artifacts_path / \"model.pkl\")\n",
    "    save_to_pickle(preprocessor, artifacts_path / \"preprocessor.pkl\")\n",
    "\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "    registered_model = mlflow.register_model(model_uri, \"abalone_regression_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mlflow ui --host 0.0.0.0 --port 5002"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xhec-mlops-project-student",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
